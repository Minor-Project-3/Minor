{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwdbTJ_ZIw7y"
   },
   "source": [
    "# Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwA9OqE1IY53"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1O1Bg_pI1VD"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Galut_WrI4bV"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\MY PROJECT\\\\new minorp\\\\minor project\\\\train.csv\")\n",
    "\n",
    "# test data\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\MY PROJECT\\\\new minorp\\\\minor project\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvtCODUEJciM"
   },
   "source": [
    "# Data Exploration (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Mni8YItfJcSs",
    "outputId": "c880fcf3-9269-450b-ad39-c3a4af89bf88"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lRex8owXJV40",
    "outputId": "a878a1d5-58e2-4578-cb46-167ee6a2e74f"
   },
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jAUIxDOYJmvt",
    "outputId": "a385b811-8a70-4eeb-f33f-037a723040a4"
   },
   "outputs": [],
   "source": [
    "# non-hate speech related tweets\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ijAyVcYjKPc_",
    "outputId": "6def6736-d9f5-4853-faa0-26451a3af937"
   },
   "outputs": [],
   "source": [
    "# hate speech  related tweets\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mubp2OU0M2-M",
    "outputId": "e2b3fe4e-abc5-4ebb-9354-6e6d520c2f12"
   },
   "outputs": [],
   "source": [
    "# check if there are any missing values\n",
    "train.isnull().sum()\n",
    "#train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9uidliWUL9t"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G9BW8zWhKWbn",
    "outputId": "238f5172-e76a-4959-d511-90f7fb247a61"
   },
   "outputs": [],
   "source": [
    "#install tweet-preprocessor to clean tweets\n",
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iB47T9w3YNry"
   },
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Kaf60xXPryT"
   },
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5BFI2HEUm6W"
   },
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "suq-CJYUXAT8",
    "outputId": "6379536e-345b-4887-9773-dd50708fc52c"
   },
   "outputs": [],
   "source": [
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0_dHhhn2bHYL",
    "outputId": "a0690808-0cd6-4bc0-fde6-8c362af280a4"
   },
   "outputs": [],
   "source": [
    "# clean the test data and append the cleaned tweets to the test data\n",
    "test_tweet = clean_tweets(test[\"tweet\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNJ7n2jXbzwl"
   },
   "source": [
    "# Test and Train split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQJjcE_Tb4JU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the labels from the train data\n",
    "y = train.label.values\n",
    "\n",
    "# use 70% for the training and 30% for the test\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EP0vIgrcdMSM"
   },
   "source": [
    "# Vectorize tweets using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reQP8v7Gb36g"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nv02BKQ-ee_m"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "it_BrO5qehpR"
   },
   "source": [
    "Apply Support Vetor Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEXBqGBGeeG6"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# classify using support vector classifier\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SJ5l9iehjBT"
   },
   "source": [
    "# Accuracy score for SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lERS4fXwea7B",
    "outputId": "a1865915-6431-4097-d950-d7c6310fa74e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter Sentiment Analysis - Support Vector Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
